\section{Related Works}

    Publication of AlexNet in 2012 have triggered a paradigm change in image segmentation, and then
    deep learning methods have provided prominent results and became the state-of-the-art in this area in recent years \cite{quang2017automatic}.
    In this section, the studies that propose deep architectures for skin lesion segmentation are discussed.
    Table~\ref{table:summary-of-related-skin-lesion-segmentation-surveys} shows the summary of the discussed surveys.

    \citet{long2015fully} proposed an FCN from the CNNs known to be successful in semantic segmentation.
    They adapted well-known classification networks such as AlexNet, VGG, GoogleLeNet to fully convolutional networks.
    Then, to create a successful segmentation, they combined semantic details from a deep layer
    and the appearance details from a shallow layer to define a new skip architecture.
    The proposed architecture achieved remarkable results compared to state-of-the-art models on PASCAL VOC.

    \citet{ronneberger2015u} built a new neural network aimed to be able to get accurate results with insufficient data by using them more effectively.
    U-Net, the proposed network, is based on classical FCNs and consist of two symmetric paths
    namely contracting and expanding which is responsible for capturing the context and enabling precise localization respectively.
    The new neural network proved its success with very few images by  winning the International Symposium on Biomedical Imaging (ISBI) 2015 Cell Tracking Challenge.
    In addition to being able to work with insufficient data, U-Net offers prominent results for training duration with images with relatively higher resolutions such as 512x512.
    In the following years, new studies showed that the proposed U-shaped network is more successful than C-Means Clustering in ISBI 2017 challenge dataset \cite{lin2017skin}.

    \citet{yuan2017automatic} introduced an improved version of FCN model using Jaccard distance as loss function.
    The aim of this network is increasing segmentation accuracy with
    solving common dermoscopic image problems such as imbalanced skin and lesion pixels, the existence of various artifacts, and irregular lesion borders.
    The proposed network achieved better results than the other state-of-the-art networks in ISBI 2016 challenge and PH2 databases.

    \citet{yuan2017automatic2} presented a new skin lesion segmentation framework base on Fully Convolutional Deconvolutional Neural Networks (CDNN).
    Their main focus is to improve network architecture rather than pre and post processings.
    Rectified Linear Unit (ReLU) is used as the activation of each layer in the network except to output layer.
    Internal covariate shift is reduced by adding batch normalization to the output of CD layers.
    The proposed CDNN model won the ISBI 2017 challenge.

    \citet{yuan2017improving} improved their other skin lesion segmentation architectures by using smaller kernels to optimize the discriminant capacity of their newly proposed neural network.
    The improved version of the previous work is evaluated on the ISBI 2017 challenge dataset and placed among the top 21 in the ranking.

    \citet{bi2017dermoscopic} proposed a multistage FCN to increase segmentation accuracy of classical FCNs.
    In this network, first stage FCN focused on learning localization information and coarse appearance,
    whereas second stage FCN focused on subtle characteristics of the lesion boundaries.
    A parallel integration method is also introduced to combine the results of the first and second stage FCNs.
    \citet{yu2018melanoma} presented a novel deep neural network architecture  consisting of two stages called segmentation and classification.
    The network combines a deep learning method with a local descriptor encoding strategy for dermoscopy image recognition.
    A pretrained large image dataset is used to extract deep representations of a rescaled image.
    After that, extracted descriptors are aggregated and encoded with a Fisher Vector to get global features.
    At the end, the global features are used to classify images with the help of a support vector machine.
    The proposed network is a fully convolutional residual network (FCRN) and took second place in the segmentation category of the ISBI 2016 challenge.

    \citet{al2018skin} developed a framework for skin lesion segmentation via full resolution convolutional networks (FrCN).
    This method eliminated subsampling layers and learned the full resolution features directly.
    It is tested with ISBI 2017 challenge and PH2 datasets and has achieved better results against the well-known state-of-the-art segmentation networks such as U-Net, SegNet and FCN.

    \citet{li2018dense} introduced a new dense deconvolutional network (DDN) for skin lesion segmentation.
    The proposed network is based on residual learning. It consist of three main parts namely dense convolutional layer, hierarchical supervision (HS), and chained residual pooling (CRP).
    Dimensions of the input and output images remain unchanged in DDLs.
    CRP helps to capture contextual background features while HS is responsible for improving the prediction mask.
    They tested the network with the ISBI 2017 dataset and it achieved 86.6\% Dice coefficient indices.

    \citet{xue2018adversarial} proposed an Adversarial Neural Network (GAN), called SeGAN, based deep neural network aimed to increase accuracy of medical image segmentation.
    Classical GANs are not as good as expected in providing gradient feedback to the network, because their output is single which may not represent pixel level details of images.
    Segmentation label maps are created with the help of newly created FCN based segmentor network with a new activation function.
    Another significant improvement in the proposed network is multi-scale L1 loss function aimed to extract both local and global features which represent the relations between pixels.

    \citet{peng2019segmentation} introduced a new adversarial network based segmentation architecture consisting of a CNN based discrimination and a U-Net based segmentation networks.
    This utilized generative adversarial network is evaluated on the ISBI 2016 challenge dataset and achieved 97.0\% Accuracy rate.

    \citet{tu2019segmentation} proposed an adversarial network based deep learning framework focused on solving the imbalanced lesion-background problem.
    The segmentation block of the proposed network is an encoder-decoder network with Dense-Residual block. Deep supervision is utilized with a multi-scale loss function.
    The network is evaluated on the ISBI 2017 challenge dataset and gained better segmentation results than the other state-of-the-art methods participating in that challenge.

    \citet{tschandl2019domain} introduced a new FCN where pretrained ImageNet weights are being used to feed the network on ResNet34 layers which are reused as encoding layers.
    The evaluation results showed that using pretrained weights improved the segmentation score on the ISBI 2017 challenge dataset.

    \citet{ninh2019skin} proposed a SegNet architecure based FCN framework
    which aimed to decrease the number of upsampling and downsampling layers of classical SegNet architecture to reduce the learned parameters.
    The proposed network is evaluated on the ISBI 2017 challenge dataset and gained sufficient results in terms of Jaccard Index and Dice coefficient.

    \citet{mirikharaji2019learning} proposed a deep CNN framework focused on segmenting skin lesions.
    The main focus of the proposed network was the use of two different annotation set consisting of reliable and unreliable annotations.
    The reliable annotations are marked by experts and showed reliable segmentation results. This reweighting is done by a newly deployed meta-learning approach.
    The proposed network shows that using different levels of annotation noise on weighting affects the segmentation results and model robustness positively.

    \citet{sarker2019mobilegan} proposed a lightweight GAN framework, called MobileGAN, aiming to reduce the number of training parameters while keeping the segmentation accuracy high.
    They combined the channel attention module with the 1D non-bottleneck factorization networks for the generator part of the GAN.
    MobileGAN is trained with ISIC 2018 training dataset and was evaluated with ISBI 2017 challenge dataset.
    Compared to state-of-the-art models such as FCN, U-Net, or SegNet, the results showed that the proposed network had fewer parameters, about 2.3 million, and achieved considerable scores.

    \citet{lei2020skin} proposed a GAN framework aiming to increase skin lesion segmentation accuracy and won the first part of ISBI 2017 challenge.
    The segmentation part of the proposed GAN was construct with a skip connection and dense convolution U-Net while the discrimination part was consist of a dual discriminator module.
    One of the discriminators was responsible for increasing the detection of boundaries while the other one was responsible for learning the contextual informations.

    \citet{zafar2020skin} proposed an automated neural network architecture aimed to segment skin lesion accurately.
    Res-Unet, the proposed network, is a combination of two well-known neural networks in image segmentation namely U-Net and ResNet.
    The other major improvement in this network is using image inpainting for hair removal.
    It was evaluated on the ISBI 2017 challenge and PH2 datasets and gained Jaccard Index of 77.2\% and 85.4\%  respectively.

    \citet{xie2020mutual} introduced a CNN variant, called MB-DCNN, which consisted of three sub CNNs namely coarse segmentation network,
    mask guided segmentation network, and enhanced segmentation network respectively.
    The first network was responsible for creating coarse masks which had been used on the next network to classify the lesions.
    The third network was a segmentation network fedded from the second classification network.
    There were learning transfer between networks to increase the segmentation accuracy.
    MB-DCNN was tested with the ISBI 2017challenge and PH2 datasets and it achieved Jaccard index of 80.4\% and 89.4\%.

    \input{02-related-works/tables/summary-of-related-skin-lesion-segmentation-surveys}
